# [ë°°í¬ ì‹œì—ë§Œ] chromadbì˜ sqlite3 ë²„ì „ ë¬¸ì œ í•´ê²° 
# requirements.txt ì— pysqlite3-binary ì¶”ê°€
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

# proto8 : StatGPT-2.0(ì´ì „ëŒ€í™” ê¸°ì–µ)
# ëŒ€í™” historyê°€ ì €ì¥ë˜ê³ ,
# ì‚¬ìš©ìê°€ ë¯¸ë¦¬ ì €ì¥í•œ Chroma DBì˜ ë°ì´í„°ë¥¼ ì´í•´í•œ ìƒíƒœì—ì„œ,
# ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ "langchain.RetrievalQA"ìœ¼ë¡œ ë‹µë³€"í•˜ëŠ” ì±—ë´‡(ì¶œì²˜ ì œê³µ)
# + ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•´ì„œ ë‹µë³€ ìƒì„±

import streamlit as st
import os
import time

# api key
# from dotenv import load_dotenv
# load_dotenv()
import openai
openai.api_key = st.secrets["OPENAI_API_KEY"]

# llm : langchain.ChatOpenAI
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.document_loaders import DirectoryLoader
from langchain.embeddings.openai import OpenAIEmbeddings
# from langchain_openai import OpenAIEmbeddings
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma


### â˜…â˜…â˜… í—¤ë“œ â˜…â˜…â˜…
st.markdown("# ğŸ”ì œ2ì˜ë‚˜ë¼ GPT")


### st.session_stateì— ëŒ€í™” ë‚´ìš© ì €ì¥

# ëª¨ë¸ ì´ˆê¸°í™” with st.session_state
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"     # LLM ëª¨ë¸ ì„¤ì • : "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"

# ëŒ€í™” ì´ˆê¸°í™” with st.session_state
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì—­í• (role)ê³¼ ëŒ€í™”ë‚´ìš©(content) key ì´ˆê¸°í™”
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


### Chroma dbì— ì„ë² ë”©ëœ ë°ì´í„° ì €ì¥

# dataë””ë ‰í† ë¦¬ ë¬¸ì„œë“¤ ë¡œë“œí•˜ê¸°
directoryloader = DirectoryLoader('./data', loader_cls=TextLoader)   # glob="*.txt", 

def data_to_db(loader):
    documents = loader.load()
    # print(documents)

    # Split texts
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)
    texts = text_splitter.split_documents(documents)

    # db(chroma db)ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì§€ì •
    persist_directory = 'db'

    # ì„ë² ë”©
    # embedding = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
    embedding = OpenAIEmbeddings()

    # dbì— ì„ë² ë”©ëœ ë°ì´í„° ì €ì¥
    db = Chroma.from_documents(
        documents=texts, 
        embedding=embedding, 
        persist_directory=persist_directory) 

    # db ì´ˆê¸°í™”
    db.persist()
    db = None

    db = Chroma(
        persist_directory=persist_directory, 
        embedding_function=embedding)

    return db

db = data_to_db(directoryloader)

### ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì™”ì„ ë•Œ, ì‚¬ìš©ìì™€ ì±—ë´‡ì˜ ëŒ€í™” ìƒì„±

# â˜…â˜…â˜… ì‚¬ìš©ì ì¸í’‹ ì°½ â˜…â˜…â˜…
if input := st.chat_input("What is up?"):   # â˜…â˜…â˜… ì‚¬ìš©ì ì¸í’‹ ì°½ â˜…â˜…â˜…
    
    # ì‚¬ìš©ì ì…ë ¥ì„ st.session_stateì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": input})   

    # â˜…â˜…â˜… ì‚¬ìš©ì ì•„ì´ì½˜ â˜…â˜…â˜…
    with st.chat_message("user"):     
        # â˜…â˜…â˜… ì‚¬ìš©ì ì…ë ¥ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥
        st.markdown(input)        
        print("input:", input, "\n")

    # ì±—ë´‡ ëŒ€ë‹µ
    # â˜…â˜…â˜… ì±—ë´‡ ì•„ì´ì½˜ â˜…â˜…â˜…
    with st.chat_message("assistant"):

        # ì±—ë´‡ ëŒ€ë‹µ ìƒì„± : ë¹ˆ placeholder ìƒì„± í›„ í•œ ì¤„ì”© ì±„ì›Œê°€ê¸°
        message_placeholder = st.empty()    # ë¹ˆ placeholder ìƒì„±
        full_response = ""
    
        # ï¼ ï¼ ï¼  ì±—ë´‡ ëŒ€ë‹µ(full_response->str) ìƒì„± ëª¨ë¸ë§

        # ë‹µë³€ ìƒì„± ëª¨ë¸ : langchain.RetrievalQA
        # db : ChromaDB

        ## dbì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°(ê²°ê³¼ë¥¼ kê°œ ë°˜í™˜)
        retriever = db.as_retriever(search_kwargs={"k": 2})

        ## RetrievalQA êµ¬ì„±í•˜ê¸°
        qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model='gpt-4o'),      # gpt-4o, gpt-3.5-turbo
            # OpenAI("gpt-3.5-turbo"), 
            chain_type="stuff", 
            retriever=retriever, 
            return_source_documents=True)

        def process_llm_response(llm_response):
            source_list = []
            print(llm_response['result'])
            print('\n\nSources:')
            for source in llm_response["source_documents"]:
                print(source.metadata['source'])
                source_list.append(source.metadata['source'])
            print("\n")
            return source_list
        
        def qa_bot(query):
            llm_response = qa_chain(query)
            source_list = process_llm_response(llm_response)
            return llm_response['result'], source_list

        full_response, source_list = qa_bot(input)

        # ï¼ ï¼ ï¼  

        # â˜…â˜…â˜… full_response(ì „ì²´ ë‹µë³€ string)ì„ í™”ë©´ì— ì¶œë ¥í•˜ê¸°
        message_placeholder.markdown(full_response)
        st.write("ì¶œì²˜ : ", source_list[0].replace('data\\', '').replace('.txt', '').replace('./data/',''))   # ì¶œì²˜ í™”ë©´ì— í‘œì‹œ

    # ìƒì„±ëœ ì±—ë´‡ ë‹µë³€ì„ st.session_stateì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # ì±—ë´‡ ë‹µë³€ì„ ì±„íŒ… í™”ë©´ì— í‘œì‹œ
    message_placeholder.markdown(full_response)
    print("session_state: \n", st.session_state['messages'], "\n")

    # ì‚¬ìš©ì ì¸í’‹ë“¤ë§Œ ë”°ë¡œ íŒŒì•…
    input_data = [x['content'] for x in st.session_state['messages'][0::2]]
    print(input_data)

    # ì‚¬ìš©ì inputì„ input_data.txt íŒŒì¼ì— ì €ì¥í•˜ê¸°
    if not os.path.exists('data/input_data.txt'):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ 'write' ëª¨ë“œë¡œ íŒŒì¼ì„ ìƒì„±
        with open('data/input_data.txt', 'w', encoding='utf-8') as file:
            # input ì…ë ¥
            file.write(input + "\n\n")
    else:
        # íŒŒì¼ì´ ìˆìœ¼ë©´ 'append' ëª¨ë“œë¡œ íŒŒì¼ ì—´ê¸°
        with open('data/input_data.txt', 'a', encoding='utf-8') as file:
            # input ì…ë ¥
            file.write(input + "\n\n")
    
    # input ë°ì´í„° dbì— ì¶”ê°€í•˜ê¸°
    textloader = TextLoader("./data/input_data.txt")   # state_of_the_union.txt
    db = data_to_db(textloader)
    time.sleep(0.1)














